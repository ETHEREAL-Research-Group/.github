# ETHEREAL: Enabling Autistic Voices Through Extended Reality

Welcome to the GitHub repository for ETHEREAL, a collaborative research group between the University of Calgary and the University of Virginia. This repository serves as the central hub for our extended reality (XR) solutions for nonspeaking autistic individuals.

## About ETHEREAL

ETHEREAL is dedicated to advancing the field of extended reality to enhance the lives of nonspeaking autistic individuals. We leverage immersive technologies to provide engaging and customized learning experiences, improve communication skills, and empower individuals with new opportunities.

## Key Publications

### [Grab-and-Release Spelling in XR: A Feasibility Study for Nonspeaking Autistic People Using Video-Passthrough Devices](https://doi.org/10.1145/3715336.3735719)

Summary: This paper introduces LetterBox, a video-passthrough XR application designed for nonspeaking autistic individuals to spell using a "grab-snap-release" interaction. Developed for affordable headsets like the Meta Quest, the system supports three immersion levels and dynamically tracks caregiver presence. In a study with 19 participants across four sites, all completed multi-phase spelling tasks while tolerating the headset, and most provided independent responses with minimal support. Findings show that XR-based grab interactions are feasible and offer a promising alternative to tapping for users with motor control challenges, providing design insights for accessible assistive technologies.

### [AR-Based Embodied Avatar Assistance for Nonspeaking Autistic People? Design and Feasibility Study](https://doi.org/10.1145/3715336.3735807)

Summary: This work introduces an AR-based remote presence system that enables immersive, collaborative spelling instruction for nonspeaking autistic individuals. The system uses holographic letterboards and fully embodied avatars with real-time head and hand tracking to support interaction between students and caregivers. In a study with 18 participants, the majority completed avatar-supported sessions, reporting higher engagement and a preference for avatar-based interaction over voice-only support. These results highlight the potential of AR telepresence for accessible, inclusive communication training.

### [Evaluating Gaze Interactions within AR for Nonspeaking Autistic Users](https://doi.org/10.1145/3641825.3687743)

Summary: HoloGaze is an AR gaze-based system designed to support nonspeaking autistic individuals in learning to type using eye movements. The system offers two interaction modes: gaze-only and gaze+click. In a study with 14 participants, the majority successfully completed typing tasks using HoloGaze. These findings offer valuable insights for the design of future eye-tracking assistive technologies.

### [From Letterboards to Holograms: Advancing Assistive Technology for Nonspeaking Autistic Individuals with the HoloBoard](https://doi.org/10.1145/3613904.3642626)

Summary: Presents HoloBoard, an AR system designed to help nonspeaking autistic individuals transition to more independent communication by using a virtual letterboard. In a study with 23 participants, most were able to spell words and perform complex tasks without the need for a human assistant, demonstrating the system's potential to enhance autonomy and provide new social and educational opportunities.

### [Towards an Augmented Reality Agent to Support Communication for Nonspeaking Autistic People](https://doi.org/10.1145/3613905.3651063)

Summary: Describes the development of an AR system for nonspeaking autistic individuals to practice spelling using a virtual educator. By modeling interactions from recorded sessions, the virtual educator can effectively mimic a real educator, offering a more accessible and independent method for communication training.

### [Personalizing an AR-based Communication System for Nonspeaking Autistic Users](https://doi.org/10.1145/3640543.3645153)

Summary: Investigates the use of Behavioral Cloning (BC) for the purpose of creating a personalized and adaptive placement policy for a virtual letterboard within AR for nonspeaking autistic individuals. This approach aims to reduce reliance on human assistants, thereby enhancing autonomy and privacy in communication, and demonstrates improved accuracy over non-ML methods.

### [AR-Based Educational Software for Nonspeaking Autistic People - A Feasibility Study](https://doi.org/10.1109/ISMAR59233.2023.00069)

Summary: Investigates the feasibility of using head-mounted AR applications to provide meaningful academic content for nonspeaking autistic individuals, addressing limitations in traditional education approaches.

### [Can Cross-Reality Help Nonspeaking Autistic People Transition to AR Typing?](https://doi.org/10.1145/3544549.3585859)

Summary: Explores the transition phase from traditional communication methods to augmented reality typing, aiming to facilitate motor skills development for independent typing in nonspeaking autistic individuals.

### [Interactive AR Applications for Nonspeaking Autistic People? - A Usability Study](https://doi.org/10.1145/3544548.3580721)

Summary: Examines the usability of head-mounted AR devices for nonspeaking autistic individuals through a study involving an interactive application, emphasizing the importance of understanding their tolerance and interaction with virtual objects.

### [HoloType-CR: Cross Reality Communication Training for Minimally Verbal Autistic Persons](https://doi.org/10.1109/ISMAR-Adjunct57072.2022.00042)

Summary: Introduces HoloType-CR, an immersive typing training system designed for minimally verbal autistic individuals, aiming to make communication training more accessible and cost-effective through cross-reality approaches.

### [Holotype: Lived Experience-Based Communication Training for Nonspeaking Autistic People](https://doi.org/10.1145/3491101.3519869)

Summary: Addresses the gap in technology support for nonspeaking autistic individuals by incorporating insights from lived experiences into an augmented reality communication training prototype, emphasizing personalized learning environments to develop expressive written communication skills.

## Getting Started

To explore our projects, access the codebase, or contribute to our research, please refer to the individual project repositories. We welcome collaboration and contributions from the community to advance our shared mission.

Feel free to contact us at [ethereal@ucalgary.ca] for inquiries, collaboration opportunities, or further information.

Thank you for your interest in ETHEREAL!
